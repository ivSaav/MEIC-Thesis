\chapter{Adversarial Anomaly Detection}\label{chap:aad}
In recent years, the use of Generative Adversarial Networks (GANs) has been explored in the context of anomaly detection. The main idea is to train a GAN to learn the normal distribution and then use one or all modules to detect anomalies. This chapter presents the main concepts of GANs and how they can be used for anomaly detection in solar wind profiles. Additionally, every experiment that was undertaken with this purpose will be explained. 

The chapter is organized as follows. Section \ref{sec:gan_background} introduces the GANs training process, common problems and their application for anomaly detection. Section \ref{sec:gan_experiments} presents the experiments undertaken in this thesis to detect anomalies in solar wind profiles. Section \ref{sec:ml_experiments_gan} explains the experiments undertaken with the ML prediction model after anomaly detection in the training data. Finally, Section \ref{sec:gan_summary} provides an overview of the work done in this chapter.

\section{Generative Adversarial Networks}\label{sec:gan_background}
GANs were first introduced by Goodfellow et al. in their paper "Generative Adversarial Nets" \cite{goodfellow.etal_GenerativeAdversarialNets_}. Since then, many variations of GANs have surfaced and been applied to different areas like human face generation, image-to-image and text-to-image translation, and semantic generation, among others. The original GAN consisted of two models, a generator $G$ and a discriminator $D$. The task of the first model was to capture the distribution of the data and generate new examples from that distribution. The function of the discriminator $D$ is to distinguish actual samples from the fake data generated by $G$. The two components play an adversarial game in which $G$ tries to fool $D$ with increasingly realistic examples, and in turn, $G$ tries to detect the fake samples from $G$. The authors proposed an analogy that would help the problem's dynamics:

\noindent\textit{The generative model can be thought of as analogous to a team of counterfeiters trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods until the counterfeits are indistinguishable from the genuine articles.} (\cite{goodfellow.etal_GenerativeAdversarialNets_})

The problem is formulated as follows:
\begin{equation}
    \underset{G}{min}\ \underset{D}{max}\ V(D,G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z))]
    \label{eq:gan_min_max}
 \end{equation}

 \noindent where $x$ represents the data, $z$ the latent space,  $p_{data}(x)$ is the distribution of the data and $p_z(z)$ is the distribution of the latent points (usually Gaussian) that $G$ uses to generate new samples. GANs can then be defined as a minimax game where $D$ tries to maximize $V$, as it tries to recognize generated and real images better; and, on the other hand, $G$ wants to minimize the function $V$ because its goal is to fool $G$ as many times as possible. 


\subsection{Common Challenges in the Training Phase}
Earlier GAN architectures were very unstable and hard to train. Despite some proposed solutions to these issues (\cite{radford.etal_UnsupervisedRepresentationLearning_2016,arjovsky.etal_WassersteinGenerativeAdversarial_}), GANs are still remarkably difficult to train. Following are some of the main problems experienced during this phase.\\

\noindent\textbf{Mode collapse.} Occurs when the GAN is incapable of reaching Nash equilibrium \footnote{Can be explained by the following analogy: Two players, Alice and Bob, chose strategies A and B; Alice has no other strategy to maximize her goal better, and Bob has no different strategy other than B to maximize his goal in response to Alice's choice (\url{https://en.wikipedia.org/wiki/Nash_equilibrium})} and is a consequence of poor generalization. It can occur when the generator $G$ only creates samples from a subset of the data distribution or only learns part of the distribution. The leading causes for this issue can be attributed to a poor choice of the objective function (\cite{saxena.cao_GenerativeAdversarialNetworks_2022}). In other words, $G$ focuses on a small subset of samples that consistently fool the discriminator $D$.\\

\noindent\textbf{Vanishing gradients.} The discriminator $D$ does not provide enough information for $G$ to update its gradients \cite{little.etal_GenerativeAdversarialNetworks_2021}. $D$ can distinguish real samples from fake ones with high confidence, which in turn causes the loss function of $G$ to decrease towards 0. As $D$ gets better, the gradient of $G$ progressively decreases until virtually none of the layers are updated, and $G$ can't generate samples with new distributions. Some solutions for this problem include batch normalization and clipping.\\

\noindent\textbf{Evaluation metrics.} Due to their wide range of applications, no global evaluation function can be applied to every GAN. The evaluation function varies greatly from the context of the problem in which the GAN was used. In some instances, like image generation, the principal evaluation criteria are still done qualitatively (the outputs are analyzed by humans, who determine their quality). Evaluation functions are an essential part of machine learning and allow for the correct conclusions to be made \cite{saxena.cao_GenerativeAdversarialNetworks_2022}.

\subsection{Anomaly Detection with GANs}\label{sec:gan_anomaly_detection}
Several approaches can be employed when using GANs for anomaly detection. The simplest one is to train both $G$ and $D$ on the normal data distribution and then use the latter to classify new samples as normal or anomalous. This is not always possible as the discriminator only learns to distinguish between samples from the generator and real ones. There is no guarantee that the discriminator will be able to distinguish between normal and anomalous samples, as it might have only learned specific characteristics of $G$ that are not present in the anomalous samples.

To circumvent this issue, some studies \cite{ngo.etal_FenceGANBetter_2019, liu.etal_GenerativeAdversarialActive_2020} proposed changing the focus of the vanilla GAN to be more appropriate for anomaly detection tasks. Instead of learning the normal distribution $G$ is forced to only generate anomalous samples. By forcing $G$ to generate samples close, but not equal to the normal distribution, the discriminator $D$ will learn to distinguish between normal and anomalous samples. To accommodate this, small changes to the loss functions of $D$ and $G$ are made. The results are promising, but by altering the loss functions, the new implementations might have new issues that were not experienced in other implementations.

Other studies \cite{li.etal_MADGANMultivariateAnomaly_2019, zenati.etal_AdversariallyLearnedAnomaly_2018, bashar.nayak_TAnoGANTimeSeries_2020} have proposed employing $G$ as a way to detect anomalies. These approaches are usually based on the reconstruction error of $G$ to detect anomalies, which is calculated by measuring the distance of the current sample to its closest reconstruction created by $G$. Then, an anomaly detection score can be construed with this error, either alone or in combination with the classification of the discriminator. Defective samples will, in theory, have higher reconstruction errors and will be classified as anomalous by the discriminator, as both modules didn't learn to generate or classify them correctly.

More recently, the use of adversarial autoencoders (AAE) has been proposed \cite{zenati.etal_AdversariallyLearnedAnomaly_2018,wang.etal_AdVAESelfadversarialVariational_2020} to simultaneously encode/decode an input sample and constrain its latent space representation to a prior distribution. The encoder and decoder are trained simultaneously with the discriminator, which is trained to distinguish between the latent space distribution and the prior distribution. The encoder is then used to encode new samples to the learned latent space. The discriminator classifies the latent representation of the sample as being real or fake. Similar to all other approaches, the anomaly score can be calculated by using only the reconstruction error of the decoded sample, or by combining it with the classification of the discriminator.

Some of these methods will be employed in the experiments of this thesis. The next section explains the different approaches used to detect anomalies in solar wind profiles with the help of adversarial learning.

\section{Experiments}\label{sec:gan_experiments}
This section explains the experiments performed to detect anomalies in solar wind profiles. In total, five different architectures were used for this task. One linear GAN, three RNN-based GANs (two of which are preliminary experiments), and one adversarial autoencoder.

\subsection{Anomaly Scores}\label{sec:gan_anomaly_scores}
Three anomaly detection methods are used in each experiment to detect anomalies in solar wind profiles. At the end of each experiment, the most suitable anomaly detection method was chosen based on a qualitative analysis of the results. Each approach generates a different normality score for a given sample. The scores are then used to determine a threshold of normality based on the percentage of anomalies in the dataset. This is a hyperparameter that must be determined by the user.

The first and simplest score is the classification of the discriminator, $D$. The values of the classification can range from 0 to 1, where values equal to 1 indicate a real sample and values closer to 0 indicate a fake label. The classification score is calculated by feeding the sample to the discriminator and obtaining the classification value. The abnormality classification score of a sample, $x$, is calculated as follows:

\begin{equation}
    D_{s} = 1 - D(x)
\end{equation}

The second score is the reconstruction error of the generator, $G$, and is based on the reconstruction technique of MAD-GAN \cite{li.etal_MADGANMultivariateAnomaly_2019}. The reconstruction process, expressed in algorithm \ref{alg:mse_reconstruction}, occurs iteratively for each ith sample, $x^i$, in the testing dataset. Like in the original method, the optimal latent representation for $x^i$ is obtained by first sampling a latent space variable, $z^k$. Then, for a predefined set of iterations, $j$, the generator $G$ is used to generate a batch of reconstructions $G(z^{k})$. Contrary to \cite{li.etal_MADGANMultivariateAnomaly_2019}, the distance between the original sample $x^i$ and the reconstructed one, $G(z^{k})$ is calculated using the MSE loss function. In the next step, the residuals of the MSE functions are averaged and used to update the parameters of $z^{k}$. After $j$ iterations, the latent representation, $z^{k}$, that results in the best reconstruction of $x^i$ is returned.
\\\\
\noindent\makebox[\textwidth][c]{%
\begin{minipage}{0.7\linewidth}
    \begin{algorithm}[H]
        \caption{MSE Reconstruction}\label{alg:mse_reconstruction}
    \begin{algorithmic}
        \Input
            \Desc{$x^i$}{Input Batch}
            \Desc{$n$}{Number of iterations}
        \EndInput
        \Output
            \Desc{$z^k$}{Optimal latent representation}
            \Desc{$R_{err}$}{MSE Reconstruction error}
        \EndOutput
    \end{algorithmic}

    \BlankLine
    \emph{Get a sample from the latent space}\;
    $z^k = random\_sample()$\;
    \For{$j = 0$ \KwTo $n$}{
        \emph{Reconstruct batch from $z^k$ and calculate loss}\;
        $R_{err} = MSE(x^i, G(z^k))$\;
        \emph{Update latent representation based on $R_{err}$}\;
        $z^{k} = update(z^k, R_{err}$)\;
        }
    \end{algorithm}
\end{minipage}}

The reconstruction error is calculated directly with the MSE loss between the real and reconstructed batches from the optimal latent representation, $z^{k}$. The reconstruction error is calculated as follows:

\begin{equation}
    R_{err} = MSE(x^i, G(z^{k}))
\end{equation}



The next score is a combination of the previous two scores as a way of taking advantage of both the discriminator and the generator in the detection process. The reconstruction process is similar to the previous one, but instead of using only the MSE loss, the classification score, $D_{s}$ of the discriminator, is also used. The new altered loss function is defined as follows:

\begin{equation}
    RD_{err} = MSE(x^i, G(z^{k})) \times D_{s}
\end{equation}

The reconstruction process with the discriminator input is shown in Algorithm \ref{alg:mse_reconstruction}. It is very similar to Algo. \ref{alg:mse_reconstruction}, but with the addition of the discriminator classification score to the loss function. In each reconstruction step, $j$, the discriminator classification, $D_s$, for the reconstructed batch is obtained. Then, the error between the reconstructed batch and the original data is measured with the MSE loss function. In this step, the results of the discriminator classification are multiplied by the $D_s$ score from the previous step. Finally, the parameters of $z^k$ are updated in accordance with the error that was obtained.
\\

\noindent\makebox[\textwidth][c]{%
\begin{minipage}{0.7\linewidth}
    \begin{algorithm}[H]
        \caption{MSE-Discriminator Reconstruction}\label{alg:mse_discr_reconstruction}
        \begin{algorithmic}
            \Input
                \Desc{$x$}{Input Batch}
                \Desc{$n$}{Number of iterations}
            \EndInput
            \Output
                \Desc{$z^k$}{Optimal latent representation}
                \Desc{$RD_{err}$}{MSE-Discr. Reconstruction error}
            \EndOutput
        \end{algorithmic}
        
        \BlankLine
        \emph{Get a sample from the latent space}\;
        $z^k = random\_sample()$\;
        \For{$j = 0$ \KwTo $n$}{
            \emph{Obtain $D$ classification for reconstructed batch}\;
            $D_s = 1 - D(G(z^k))$\;

            \emph{Reconstruct batch from $Z^k$ and calculate loss}\;
            $RD_{err} = MSE(x^i, G(z^k)) \times D_s$\;
            \emph{Update latent representation based on $RD_{err}$}\;
            $z^k = update(z^k, RD_{err}$)\;
        }
    \end{algorithm}
\end{minipage}}


A simplified representation of the workflow for obtaining the anomaly scores is shown in Figure \ref{fig:anomaly_detection_method}. This process is done by extracting the pre-trained $G$ and $D$ with their layers frozen. Each batch, $x^i$, is passed through $D$ to obtain the classification score, $D_s$. The reconstruction process from algorithms \ref{alg:mse_discr_reconstruction} and \ref{alg:mse_reconstruction} is performed in the invert mapping step to obtain the optimal latent representation, $z^k$, for the given test sample. After this, $R_{err}$ is calculated by comparing the reconstructed sample with the original one. The final $RD_{err}$ can be obtained by combining $R_{err}$ with $D_s$.


\begin{figure}[]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/gan_anomaly_detect_flow.png}
    \caption[Anomaly detection workflow]{Anomaly detection workflow with each defined reconstruction method. The invert mapping obtains the optimal latent representation, $z^k$, from the reconstruction error.}\label{fig:anomaly_detection_method}
    \small\textsuperscript{(1)} Only applied to the reconstruction method in algorithm \ref{alg:mse_discr_reconstruction}.
\end{figure}



\subsection{Linear GAN}\label{sec:linear_gan}

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{figures/linearGAN.png}
    \caption{Linear GAN Architecture}
    \label{fig:linear_gan_architecture}
\end{figure}


The first architecture was a linear GAN, which is a simple GAN with a linear generator and discriminator. Several experiments were performed with different configurations of the architecture. The use of BatchNorm in either module was tested to try and stabilize the training process. This proved ineffective, making it difficult for $G$ and $D$ to converge. Because of this, it was not included in the final implementation. In addition, the number of intermediate stacked linear layers was varied during the tests to try and find a configuration that worked best for this problem. 

Besides these changes, different activation functions were also tested. The activation functions used were ReLU, LeakyReLU, and Tanh, with a combination of them in the intermediate and output and input layers. Like other GAN architectures, the LeakyReLU activation function was chosen to prevent the gradient from vanishing and improve the learning process's overall stability. Most configurations that included the Tanh activation function in the output layer of the generator were discarded, as it proved ineffective during the anomaly detection phase.

The final architecture is shown in Figure \ref{fig:linear_gan_architecture}. Both the generator and discriminator are built with linear layers. The generator, $G$, consists of an input layer that takes as input a latent space variable, $z$, with $L_P$ features and outputs a sample with the same dimension as the input. The first layer linearly transforms the input noise vector and projects $z$ into lower dimensional space with 640 dimensions. The output of this layer is then passed through a LeakyReLU activation function. Next, the resulting features from this step are passed through two stacked linear layers, each with 640 dimensions. In the last layer, the features from the previous step undergo a linear transformation to project them into the same dimension as the input sample. As was previously said, no activation function is used in the output layer of the generator, as it was ineffective during the detection phase.

The discriminator, $D$, consists of an input layer that takes as input a sample with $L_P$ features and outputs a scalar value. The objective of $D$ is to progressively learn the most important features of the data to perform binary classification of the input sample as being real or fake. The first and subsequent layers transform the input data into increasingly smaller dimensions. In the output layer, the features from the previous step are projected into a single scalar value. This value is then passed through a sigmoid activation function to obtain the final classification score of each sample.

\subsubsection*{Training}
Both modules were trained with the Adam optimizer with a learning rate 0.0001 for the generator and 0.0002 for the discriminator. This was done to prevent the discriminator from overpowering the generator during training. The weights of each linear layer were initialized with the He initialization function from \cite{He.Zhang.ea_DelvingDeepRectifiers_2015}.

Two models were trained, the first one, $M_i$, to detect anomalies in the inputs of the MULTI-VP dataset and the other, $M_o$, for the outputs (refer to section \ref{sec:data_analyis}). Both models were trained over 300 epochs with a batch size of 128. In both approaches, the training data was scaled with the \textit{MinMaxScaler} to preserve the variation of extreme values in the data. The training data consisted of a matrix with $N\times L_P$ dimension, where $N$ is the number of training samples and $L_P$ is the number of features per profile. Like in the clustering experiments, the selected validation data was excluded from the training process for further use in the ML evaluation step. 

From Section \ref{sec:data_analyis}, we know that every variable in a profile has 640 features, so the total number of features per sample can be defined as $L_P = k\times 640$, where $k$ is the number of variables in a profile that is used during training. 

In $M_i$, the input data, $x$, consists of concatenating the $B [G]$ and $\alpha [deg]$ variables of each profile. The radial coordinate radius, $R [R_{sun}]$, was excluded from the process to reduce the number of features the networks needed to learn. In addition, extreme variations in the input data were removed to prevent both modules from learning noisy features that would hinder the detection process. Following the previous notation, the number of features for each sample is $L_{P_i} = 2\times 640 = 1280$.

In the outputs model, $M_o$, every output variable of MULTI-VP is used in the training phase. Each sample consists of the concatenation of the density, $n [10^{10}cm^{-3}]$,  the velocity, $v [km/s]$, and temperature, $T [MK]$, with a combined number of features per sample, $L_{P_o}$, of 1920. Contrary to the input model, no extreme variations were removed from the data, as it performed well without this step.

\subsubsection*{Anomaly Detection}
The detection step was carried out for each model with all three anomaly score functions defined at the beginning of this section. Due to the lack of validation metrics, the choice of method was based on the visual inspection of the results. The anomaly scores' stability and the dataset's quality without anomalies were considered.

Considering these criteria, the best results were obtained with the reconstruction error, $R_{err}$. The other two functions, $D_{s}$ and $RD_{err}$, were very unstable and were not able to detect the anomalies as well as $R_{err}$. The filtered input and output variables can be seen in Image \ref{fig:linear_gan_clean_in} and \ref{fig:linear_gan_clean_out}, respectively.


\begin{figure}[]
    \caption[Linear GAN filtered datasets]{Resulting datasets after the anomaly detection step with the linear GAN architecture on the inputs and outputs of the MULTI-VP dataset.}
    \label{fig:linear_gan_clean_data}
    \begin{subfigure}[h]{0.8\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/linearGAN_clean_in.png}
        \caption{Input Variables}
        \label{fig:linear_gan_clean_in}
        % \label{fig:tsne_mag_2d}
    \end{subfigure}
    \hfill
    \begin{subfigure}[h]{0.8\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/linearGAN_clean_out.png}
        \caption{Output Variables}
        \label{fig:linear_gan_clean_out}
    \end{subfigure}
\end{figure}

The first image (Figure \ref{fig:linear_gan_clean_in}) resulted from removing 10\% of the files from the original dataset based on anomaly scores. As was previously said, the anomaly scores were obtained by training the GAN model, $M_i$, in the input variables and then using $G$ to calculate the anomaly scores of each sample in the testing dataset. The results show that the data is mostly clean, with some anomalies remaining in the magnetic field, $B [G]$, variable. For the output variables (Figure \ref{fig:linear_gan_clean_out}), only 8\% of the files were excluded based on anomaly scores. The resulting output variables are mostly clean, with some abnormalities in the density, $n [cm^3]$, variable.

Overall, the experiments with this architecture prove that it can detect anomalies in the input and output variables of MULTI-VP. However, the percentage of files that need to be removed (i.e. the False Positive rate) is still very high. This might indicate that the current architecture might not be ideal for the task, as seemingly "normal" profiles might be excluded from the prediction step.


\subsection{Preliminary RNN-based GAN Experiments}\label{sec:gan_experiment_lstm}
The next experiments were with RNN-based GANs. These experiments are based on the assumption that consecutive profiles in the MULTI-VP dataset are somewhat similar and have small variances. This can be closely associated with other studies for detecting anomalies in time-series data (refer to Section \ref{sec:sota_anomaly_detection}). 

Several architectures were designed and tested first with the RNN-based GANs. These failed to produce meaningful results as the GANs were very unstable during training, and the anomaly scores could not detect any anomalies in the data. This might be due to the issues associated with traditional RNN-based architectures, such as the vanishing gradient problem \cite{Schmidt_RecurrentNeuralNetworks_2019}.

Considering this, the next batch of tests was carried out with GRU-based GANs. GRU NNs, like LSTM NNs, can learn long-term dependencies in the data sequences. However, they are less resource intensive and faster to train than LSTM NNs as they require fewer parameters. The results obtained with the GRU architectures were tested with LSTM ones to ensure that they would not change as per the choice of architecture. The performance of both architectures was similar, with the GRU-based GANs being slightly faster to train. Because of this, the results presented in this section are from GRU GAN architectures, as they are more efficient than LSTM ones, and reach similar outcomes.

\subsubsection*{Stacked GRU GAN}
Before reaching a stable RNN architecture, several experiments were carried out with different architectures. The first attempts employed multilayer GRUs for $G$ and $D$. Several iterations were tried with several recurrent layers and hidden sizes. Several tests were carried out with multiplayer GRUs, due to the high number of features for the input data. However, the results were unsatisfactory as the GANs were very unstable during training. $D$ would always outperform $G$ in this phase, causing the latter to collapse and produce meaningless results. This occurred even when $D$ had significantly fewer layers than $G$. In addition, reducing the learning rate of the discriminator didn't seem to affect the instability of the GANs. 

With this in mind, other network configurations were tested by reducing the number of features given to the stacked GRU layers. This was done by applying a linear transformation on the input data, significantly reducing its dimensionality. With this layer, in theory, only the most important attributes of the inputs would be retained and passed to the subsequent layers. This approach managed to improve the stability of the GANs during training, but the results of the detection phase were still subpar with the ones from the linear GAN.

\subsubsection*{Pyramid GRU GAN}
In the second batch of experiments, a pyramid GRU GAN was designed to circumvent the dimensionality issues of the stacked GRU GAN. This architecture consisted of a simple generator with three GRU layers and an output linear layer for activation.
The first layers would narrow the input size to smaller dimensions to ensure that only the most meaningful features would be retained. Then the last GRU layer would upscale the outputs from the previous layers into a higher dimension. In the output layer, the resulting features would suffer from a linear transformation that transformed the data into the desired output dimension of the generator. This would then be passed through the Tanh activation function.

The discriminator consisted of only two GRU and a linear output layer. Following the same logic as the generator, the first two layers progressively reduced the number of features of the input data. The output layer would reduce the features from the last layer to just one and then pass it through the sigmoid activation function for binary classification.

As in the previous experiments, the training process of the GAN became more stable; however, the results of the anomaly detection still weren't as good as the ones obtained by the linear GAN.





% \subsection{Stacked GRU GAN}
% The first attempts consisted of employing multilayer GRUs for both $G$ and $D$. Several attempts were tried with a different number of recurrent layers and hidden sizes. Due to the high number of features, $M$ of the input data, several tests were carried out with deep multilayer GRUs. However, the results were not satisfactory as the GANs were very unstable during training. $D$ would always outperform $G$ in this phase, causing the latter to collapse and produce meaningless results. This occurred even when $D$ had significantly fewer layers than $G$. In addition, reducing the learning rate of the discriminator didn't seem to affect the instability of the GANs. 

% Having these issues into consideration, other configurations of the network were tested by reducing the number of features that were given to the stacked GRU layers. This was done by applying a linear transformation on the input data that significantly reduced the dimensionality of the data. With this layer, in theory, only the most important attributes of the inputs would be retained and passed to the subsequent layers. This approach managed to improve the stability of the GANs during training, but the results of the detection phase were still subpar with the ones from the linear GAN.

% \subsection{Pyramid GRU GAN}\label{sec:pyramid_gru_gan}

% As a way of circumventing the dimensionality issues of the stacked GRU GAN, a pyramid GRU GAN was designed. This architecture consisted of a simple generator with three GRU layers and an output linear layer for activation.
% The first wot layers would narrow the input size to smaller dimensions, to make sure that only the most meaningful features would be retained. Then the last GRU layer would upscale the outputs from the previous layers into a higher dimension. In the output layer, the resulting features would suffer from a linear transformation that transformed the data into the desired output dimension of the generator. This would then be passed through the Tanh activation function.

% The first attempts consisted of using a simple Generator with four GRU layers. The first two layers would narrow the input size to smaller dimensions and then, the last layer would upscale the features into a higher dimension. Then, in the output layer, the features from the previous GRU layers would be passed through a Linear layer that would transform the data into the desired output dimension of the generator. The transformed data was then passed through the Tanh activation function. 

% The discriminator consisted of only two GRU and a linear output layer. Following the same logic as the generator, the first two layers, progressively reduced the number of features of the input data. The output layer would reduce the features from the last layer to just one, which would then be passed through the sigmoid activation function for binary classification.

% As in the previous experiments, the training process of the GAN became more stable; however, the results of the anomaly detection still weren't as good as the ones obtained by the linear GAN.


\subsection{MAD-GAN}\label{sec:madgan}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/madgan_arch.png}
    \caption[MAD-GAN Architecture]{Architecture of the MAD-GAN model. The Generator consists of three stacked GRU layers and a linear output layer. The discriminator consists of a single GRU layer and a linear output layer followed by the Sigmoid activation function. Both take as input sequences of size $N_P$.}
    \label{fig:madgan_architecture}
\end{figure}

The final architecture for this class of GANs was based on MAD-GAN \cite{li.etal_MADGANMultivariateAnomaly_2019}. It was chosen to determine if one of the most famous state-of-the-art RNN GANs for time-series data could be used to detect anomalies in the MULTI-VP dataset. The architecture of the generator and discriminator is shown in Figure \ref{fig:madgan_architecture}.

Similar to the original implementation \cite{li.etal_MADGANMultivariateAnomaly_2019}, the generator, $G$, consists of three stacked GRU layers and a linear output layer (without an activation function). The discriminator, $D$, consists of a single GRU layer and a linear output layer followed by the Sigmoid activation function. $G$ takes as inputs windows with $N_P$ latent vectors with $L_P$ features and synthesizes samples with the same dimensions. $D$ takes as inputs windows with $N_P$ real or fake samples with $L_P$ features and outputs a single value between 0 and 1, representing the probability of the input window coming from the dataset or $G$. 

In this implementation, GRU cells were employed instead of LSTM cells used in the original version. It was observed that the choice between the two cell types did not significantly impact the detection capability of the architecture. Considering this, GRU cells were preferred due to their lighter and faster nature compared to LSTMs. Accordingly, each layer of the network was composed of GRU cells, with each cell containing 200 hidden units.

\subsubsection*{Data Preparation}
Unlike the previous architecture, the data is aggregated into windows, $W$, with consecutive profiles. The size of each window, $N_P$, is a hyperparameter that needs to be tuned and indicates the number of consecutive profiles, $P$, fed into the GANs. With this formulation, the ith window, $W_i$, is defined as the set of the $N_P$ consecutive profiles of the ith profile, $P_i$, in the dataset, such that $W_i = \{P_i, P_{i+1}, ..., P_{i+N_P-1}\}$.

Each window varies in length ($L_P$) according to the number of variables used for anomaly detection. Each variable in the dataset has an equal number of features (refer to Section \ref{sec:data_analyis}); therefore, the number of features for a single profile can be expressed as $L_P=k\times 640$, where $k$ is the number of variables being used for the task. From this, the dimensions of the ith window, $W_i$, can be defined as $(N_P, L_P)$.

As in the previous experiments, two models were designed to detect anomalies in both the input and output variables used by MULTI-VP. In the model trained on the inputs ($M_i$), only the magnetic field, $B [G]$ variable, was used for the task. This was due to the problems faced in the previous RNN experiments (Section \ref{sec:gan_experiment_lstm}) due to the high dimensionality of the dataset. Additionally, the magnetic field is the variable in the dataset that seems to be most affected by the presence of anomalies. Following the notation adopted in the last paragraph, the dimensions of the ith window, $W_{i}$, in the dataset is set to $(N_P, 640)$, where 640 is the number of features $L_P$ of the $B [G]$ variable and $N_P$ is the window size.

In line with the previous experiments, the most extreme values from the input variables were removed from the training process to ensure the best performance of the GAN models. These were then used during the detection phase.

Additionally, the output model, $M_o$, was trained on the three output variables of the MULTI-VP dataset without removing extreme values. With this, the dimension of each window in the training dataset is set to $(N_P, 1920)$, where 1920 is the number of features $L_P$ of the three output variables and $N_P$ is the window size.

\subsubsection*{Training}
Several configurations were tested for the number of hidden units for the GRU layers. The best results were obtained with 200 hidden units in both modules. The learning rate was set to 0.0001 for $G$ and 0.0002 for $D$ using the Adam Optimizer. The batch size was set to 32, and the number of epochs to 100. The number of profiles per window, $N_P$, was set to 10. In addition to this, the same training method as in \cite{li.etal_MADGANMultivariateAnomaly_2019} was used. In this method, $D$ is firstly trained for a set number of iterations while $G$ is kept fixed. This ensures that $D$ learns the representation of the real data before training $G$. After this, $G$ is trained for a set number of iterations while $D$ is frozen. This process is repeated until the end of the training process. The number of iterations was 10 and 5 for $D$ and $G$, respectively.

As in the previous RNN architectures, the training process was very unstable, and the modules didn't converge due to the high number of input features. Changing the number of hidden features, the learning rate and the number of iterations didn't seem to affect the stability of the training process.

In an attempt to reduce the number of data features and in line with the additional experiments in \cite{li.etal_MADGANMultivariateAnomaly_2019}, PCA was applied to the training data. This transformation reduced the number of features, $L_P$, to a fixed 100 features per profile. For the model $M_i$, the initial 640 features from the magnetic field variable were reduced to 100 features. For $M_o$, the 1920 features from all the output variables were reduced to 100 features. With this, the dimension of both training windows was set to ($N_P, 100$).

\subsubsection*{Anomaly Detection}
The detection step for both models was carried out with the three anomaly functions defined earlier. Every anomaly score function provided overall good results, showcasing the method's stability. Despite this, the best results were obtained with the $R_{err}$ function. The results of the anomaly detection on the inputs as well as on the outputs are shown in Figure \ref{fig:madgan_clean_data}. These were obtained by training the models with the PCA-transformed data and then applying the anomaly detection step to the testing data with the model from the previous stage.

\begin{figure}
    \caption[MAD-GAN filtered datasets]{Resulting datasets after the anomaly detection step with the MAD-GAN architecture on the inputs and outputs of the MULTI-VP dataset.}
    \label{fig:madgan_clean_data}
    \begin{subfigure}[h]{0.8\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/madgan_clean_in.png}
        \caption{Input Variables}
        \label{fig:madgan_clean_in}
        % \label{fig:tsne_mag_2d}
    \end{subfigure}
    \hfill
    \begin{subfigure}[h]{0.8\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/madgan_clean_out.png}
        \caption{Output Variables}
        \label{fig:madgan_clean_out}
    \end{subfigure}
\end{figure}

Figure \ref{fig:madgan_clean_in} shows the anomaly detection results on the input variables. At first glance, the results are very similar to those obtained with the linear GAN; however, MAD-GAN only required a threshold of 3\% top anomalous profiles. This means this model is more sensitive to anomalies in the magnetic field variable than the linear GAN model. The same applies to the model trained on the output variables (Figure \ref{fig:madgan_clean_out}). These results indicate that MAD-GAN is more sensitive to anomalies in both the input and output variables than the linear GAN model, which translates to a lower False-Positive rate.

Note that these results were only possible because of the use of PCA. This might indicate that the experiments in Section \ref{sec:gan_experiment_lstm} might have worked if the same method had been employed. A possible issue with this approach is that PCA might be removing important features from the data, which could be used to improve the results of the anomaly detection step.

\clearpage
\subsection{Adversarial AE}\label{sec:aae}
In the final experiments, an adversarial autoencoder architecture was used. This architecture was chosen to determine if using an autoencoder could improve the results obtained with the previous GAN architectures. The architecture of the generator and discriminator is shown in Figure \ref{fig:aae_architecture}. 

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/aae_arch.png}
    \caption[Adversarial Autoencoder Architecture]{Architecture of the adversarial autoencoder. The generator $G$, consists of an encoder, $Enc$, and decoder, $Dec$. The job of the first is to generate a latent representation of the input data, which is then used by the decoder to reconstruct the input. The discriminator, $D$, takes the latent representation generated by $Enc$ as inputs and outputs a single value between 0 and 1, representing the probability of the input coming from the prior distribution or $Enc$.}
    \label{fig:aae_architecture}
\end{figure}

The generator, $G$, is divided into an encoder, $Enc$, and decoder $Dec$. The objective of $Enc$ is to generate a latent representation of the input data. This latent representation is then used by $Dec$ to reconstruct the input data. In adversarial autoencoders, a discriminator model is also introduced to constrain the latent representation to follow a prior distribution. In this case, the discriminator, $D$, takes the latent representation generated by $Enc$ as input and outputs a single value between 0 and 1, representing the probability of the input coming from the prior distribution or $Enc$.

\subsubsection*{Training}
The loss function combines the reconstruction loss of the autoencoder (Equation \ref{eq:ae_objective_func}) with the adversarial loss of the discriminator. The reconstruction loss is the mean squared error between the input to de encoder and the decoder output. The adversarial loss is the binary cross-entropy loss between the output of the discriminator and the prior distribution. The loss function is defined as follows:

\begin{equation}\label{eq:aae_objective_func}
    \mathcal{L}_{AAE} = \alpha \times \mathcal{L}_{AE} + (1-\alpha) \times \mathcal{L}_{ADV}
\end{equation}

where $\alpha$ is a hyperparameter that controls the weight of the reconstruction and adversarial losses.

The training process consists of first training the autoencoder and freezing the discriminator parameters. In this step, the encoder, $Enc$, generates a latent space representation of the original data, which is then reconstructed by the decoder, $Dec$. The parameters of the encoder and the decoder are updated with the equation \ref{eq:aae_objective_func}. After this, $D$ is trained while the encoder and decoder are kept frozen. In this step, the discriminator is trained to distinguish between the latent representation generated by the encoder and the prior distribution. With this, $D$ is conditioned to learn the prior distribution and to classify the encoded samples more precisely. This process is repeated until the end of the training phase.

The AAE was trained over 400 epochs with the help of the Adam Optimizer, with a learning rate of 0.0002 for $D$ and 0.0001 for $G$. The batch size was set to 128, and the hyperparameter $\alpha$ was set to 0.999. The prior distribution was set to two distinct 2D Gaussian distributions. 

Like in the previous experiments, a model ($M_i$) was trained for the input variables and another ($M_o$) for the output variables. For the first, only the magnetic field variable (without extreme values) was used as input, while all the output variables were used for the second.

\subsubsection*{Anomaly Detection}

The anomaly detection step was carried out with the same anomaly functions as in the previous experiments; however, the generator reconstruction step is done directly with the autoencoder without the need for the invert mapping in algorithms \ref{alg:mse_discr_reconstruction}, \ref{alg:mse_reconstruction}.

The autoencoder proved more than capable of detecting data anomalies without a discriminator. However, as previously stated, this approach aims to take advantage of the reconstruction abilities of the autoencoder along with the discriminator to improve the results of the baseline autoencoder. The results of the anomaly detection step are shown in Figure \ref{fig:aae_clean_data}.

\begin{figure}
    \caption[AAE filtered datasets]{Resulting datasets after the anomaly detection step with the AAE architecture on the inputs and outputs of the MULTI-VP dataset.}
    \label{fig:aae_clean_data}
    \begin{subfigure}[h]{0.6\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aae_clean_in.png}
        \caption{Input Variables}
        \label{fig:aae_clean_in}
        % \label{fig:tsne_mag_2d}
    \end{subfigure}
    \hfill
    \begin{subfigure}[h]{0.6\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/aae_clean_out.png}
        \caption{Output Variables}
        \label{fig:aae_clean_out}
    \end{subfigure}
\end{figure}

The results show similar outcomes as in the linear GAN implementation. Both images were obtained by removing the top 10\% anomalous profiles from the dataset. The results show that the AAE is capable of detecting anomalies in the input and output variables. However, the results are not as good as the ones obtained with the MAD-GAN.


\subsection{Experiments Summary}\label{gan_experiments_summary}

\begin{table}[]
\caption{Summary of the results obtained with the different GAN architectures.}\label{tab:gan_results}
\begin{threeparttable}[b]
\begin{tabular}{@{}crrrlrrr@{}}
\toprule
\multicolumn{1}{l}{} & \multicolumn{3}{c}{Input Variables}                                                               &  & \multicolumn{3}{c}{Output Variables}                                                         \\ \cmidrule(lr){2-4} \cmidrule(l){6-8} 
\multicolumn{1}{l}{} & \multicolumn{1}{c}{Function} & \multicolumn{1}{c}{Threshold (\%)} & \multicolumn{1}{c}{Anomalies} &  & \multicolumn{1}{c}{Function} & \multicolumn{1}{c}{Threshold} & \multicolumn{1}{c}{Anomalies} \\ \cmidrule(lr){2-4} \cmidrule(l){6-8} 
Linear GAN           & Rerr                         & 10                                 & 1177                          &  & Rerr                         & 8                             & 941                           \\
MAD-GAN              & Rerr                         & 3                                  & 352                           &  & Rerr                         & 3                             & 352                           \\
AAE                  & RDerr\tnote{1}                        & 10                                 & 1177                          &  & RDerr\tnote{1}                        & 10                            & 1177                          \\ \bottomrule
\end{tabular}
\begin{tablenotes}
    \item [1] Direct reconstruction error from the generator ($Enc+Dec$) without algorithm \ref{alg:mse_discr_reconstruction}.
\end{tablenotes}
\end{threeparttable}
\end{table}

A summary of the results obtained in the detection phase with the different GAN architectures is shown in Table \ref{tab:gan_results}. From an analysis of the results, MAD-GAN cleaned the dataset with the smallest anomaly threshold. The next best architecture was Linear GAN, with the same threshold in the input variables as in AAE but a lower threshold in the outputs. Despite these architectures having the same anomaly threshold for the input variables, some anomalies that resulted from the linear GAN remained in the dataset. This might indicate that the anomaly threshold for this approach should have been higher than 10\%.

In conclusion, MAD-GAN proved to be the best architecture in the anomaly detection step. It managed to clean the dataset with the smallest anomaly threshold, preserving the most normal profiles in the dataset. The resulting datasets from this step will be used in the prediction phase, described in the next section.

Note that the MAD-GAN experiments were only made possible because of the use of PCA on the data. This might indicate that the previous preliminary experiments might also have been capable of performing well if this method had been used.


\section{ML Experiments}\label{sec:ml_experiments_gan}
After selecting an appropriate method for anomaly detection, the impact of the chosen approach was evaluated with the MULTI-VP simulation. As previously stated, the set of validation profiles excluded from the training phase was used for this step. Due to time constraints, only the clustering models from Section \ref{sec:clustering_mulivp_results} were trained without the detected anomalous profiles.

The detection was done with the input and output MAD-GAN models from the previous section. The results from detecting the input and output variables were aggregated into a single file indicating the name of every anomalous profile. 

First, a simple experiment was done to assert if excluding the anomalous profiles from the baseline model results would translate to decreased mean errors. Surprisingly this only occurred in the $n [cm^3]$ variable, while the others mainly stayed the same as the ones without anomaly removal. The same approach was tried on the clustering models obtained from the previous experiments (refer to Section \ref{sec:clustering_mulivp_results}). This showed a slight improvement in the mean error in each variable compared to the previous results.

In the second batch of experiments, we intended to discover if anomalies in the training data were hindering the prediction quality. The abovementioned anomalous profiles were excluded from the training dataset and used to train new iterations of the clustering models obtained in the previous experiments. Following the same methodology as before, the predictions of the validation dataset of these new models were fed to the MULTI-VP simulation as initial flow estimates. The anomalous files in the validation dataset were also excluded from the evaluation metrics, which means that the predictions of the new models on anomalous are being ignored in the evaluation.


\begin{figure}[h]
    \caption[Clustering and GAN MULTI-VP error comparison for N]{Error comparison of $n [cm^3]$. \emph{(a)} shows the mean error comparison of the results from the previous clustering experiments (without anomalous profiles) and the expert estimates; \emph{(b)} is the mean error comparison of the clustering models trained on datasets without anomalies and the original expert estimates.} 
    \begin{subfigure}[]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/N_error_comparison_after100_clusters_gan_selected.pdf}
        \caption{Clustering GAN selected}
        \label{fig:n_clusters_gan_selected}
    \end{subfigure}
    \hfill
    \begin{subfigure}[]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/N_error_comparison_after100_clusters_anomaly_gan_selected.pdf}
        \caption{Clustering Clean Dataset}
        \label{fig:n_error_clusters_anomaly_selected}
    \end{subfigure}
\end{figure}

Figure \ref{fig:n_clusters_gan_selected} shows the results from the original clustering models on the $n [cm^3]$ variable without the anomalous profiles detected by MAD-GAN. Surprisingly, the results of this experiment are substantially worse than the ones obtained in the clustering experiments without removing anomalous profiles. This can be because the detection method identified anomalies in other variables that did not constitute anomalies in $n [cm^3]$, which might have skewed the mean of the errors. % TODO rever sus

On the other hand, the predictions obtained with the new clustering model trained on the clean dataset generate better predictions than in both cases. This improvement is evident in Figure \ref{fig:n_error_clusters_anomaly_selected} where the mean error of $v$ is more concentrated around zero. A smaller mean error indicates that the predicted values are closer to the actual values, indicating a higher level of accuracy in the forecasting process.


\begin{figure}[h]
    \caption[Clustering MULTI-VP error comparison for V]{Abscissa wise estimate error comparison of $v [km/s]$. \emph{(a)} shows the mean error comparison of the results from the previous clustering experiments (without anomalous profiles) and the expert estimates; (b) compares the results of the clustering models when trained on the clean dataset with the expert estimates.}
    \begin{subfigure}[]{0.48\textwidth}
        \centering
            \includegraphics[width=\textwidth]{figures/V_error_comparison_after100_clusters_gan_selected.pdf}
            \caption{Clustering GAN selected}
        \label{fig:v_error_clusters_gan_selected}
    \end{subfigure}
    \hfill
    \begin{subfigure}[]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/V_error_comparison_after100_clusters_anomaly_gan_selected.pdf}
        \caption{Clustering Clean Dataset}
        \label{fig:v_error_clusters_anomaly_selected}
    \end{subfigure}
\end{figure}

Figure \ref{fig:v_error_clusters_gan_selected} demonstrates a slight reduction in error when compared to the clustering model that did not involve anomaly removal. However, the results obtained from the new clustering models trained on the clean dataset (depicted in Figure \ref{fig:v_error_clusters_anomaly_selected}) show worse performance than the previous models. This discrepancy is particularly noticeable in the range between abscissa values 300 and 400, where the error in the new models is considerably higher than that of the previous approach. Despite this observation, it is essential to note that the new clustering models outperformed the baseline model and the original expert estimates regarding predictive accuracy.

The analysis of temperature data reveals significant differences compared to the results obtained from the initial clustering models (Figure \ref{fig:t_error_baseline}). Figure \ref{fig:t_error_cluster_no_overfit} presents the outcomes of the new model trained on the clean dataset, showcasing a higher mean error than the first clustering model. This discrepancy is particularly pronounced from abscissa value 300 onwards. The higher mean error in this range indicates that the new model failed to effectively learn the underlying features and patterns of the temperature lines. As a result, its estimates for temperature values in this specific range are even worse than the estimates provided by initial experts. This finding suggests there may be specific characteristics or complexities in the temperature data that the new model could not capture effectively. It is possible that the clean dataset used for training lacked crucial information or representative samples in the range where the model performed poorly.

\begin{figure}[h]
    \caption[Clustering MULTI-VP error comparison for T]{Abscissa wise error comparison of $T [MK]$. (a) shows the mean error comparison of the results from the previous clustering experiments (without anomalous profiles) and the expert estimates; (b) is the mean error comparison of the clustering models trained on datasets without anomalies and the original expert estimates.}
    \begin{subfigure}[]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/T_error_comparison_after100_clusters_gan_selected.pdf}
        \caption{Cluster models (no anomaly training)}
        \label{fig:t_error_baseline}
    \end{subfigure}
    \hfill
    \begin{subfigure}[]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/T_error_comparison_after100_clusters_anomaly_gan_selected.pdf}
        \caption{Baseline (no anomalies)}
        \label{fig:t_error_cluster_no_overfit}
    \end{subfigure}
\end{figure}

The findings suggest that training the clustering model on a clean dataset leads to worse predictions, as evidenced by the increased mean error in the velocity and temperature variables. This approach only seemed to work for the $n [cm^3]$ variable, with it having estimates closer to the ones the simulation outputs.


\section{Summary}\label{sec:gan_summary}
In this chapter, the use of adversarial learning was explored for the detection of anomalies in solar wind profiles. Section \ref{sec:gan_background} provides background knowledge on generative adversarial networks. Section \ref{sec:gan_experiments} details the various adversarial methods used to filter anomalies from the dataset, with the most efficient one being MAD-GAN. 

Finally, the last section shows the results of the MULTI-VP simulation when using the new approach. In it, we show that removing anomalous profiles from the previous results would produce better mean errors for the estimates, which indicates that broken files harm the overall results. Surprisingly, the clustering models trained without anomalous profiles failed to produce better estimates for the $V$ and $T$ variables, with the ones from the clustering experiments being closer to the final simulation results.

